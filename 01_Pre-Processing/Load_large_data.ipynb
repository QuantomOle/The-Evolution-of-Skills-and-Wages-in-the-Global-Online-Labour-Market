{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and transform a very large text file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Requires a folder called 'csv' to store the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import ast\n",
    "import glob\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data_large (rawdata):        \n",
    "    \n",
    "        dict_ = {\"skills\":[],\"skills2\":[], \"rate\":[], \"amount\":[], \"job_type\":[], \"date\":[], \"description\":[],\n",
    "         \"title\":[], \"worker_ID\":[], \"op_engagement\":[], \"engagement_weeks\":[],\n",
    "         \"op_pref_english_skill\":[],\"candidates\":[], \"buyer\":[],\"category_1\":[],\"category_2\":[],\n",
    "        \"assignments\":[],\"assignment_info\":[]} \n",
    "    \n",
    "    \n",
    "        job = ast.literal_eval(rawdata)\n",
    "\n",
    "        # multiple items\n",
    "\n",
    "        ## skills 1\n",
    "\n",
    "        try:\n",
    "            skills = list(job[\"op_required_skills\"][\"op_required_skill\"].values())[0]\n",
    "        except:\n",
    "            skills = float('nan')\n",
    "        dict_[\"skills\"].append(skills)\n",
    "\n",
    "        ## skills multiple\n",
    "        try:\n",
    "            skills2 = job[\"op_required_skills\"][\"op_required_skill\"]\n",
    "            skill_list = []\n",
    "            for skill in skills2:\n",
    "                try:\n",
    "                    skill_item = list(skill.values())[0]\n",
    "                except:\n",
    "                    skill_item = float('nan')\n",
    "                skill_list.append(skill_item)\n",
    "        except:\n",
    "            skill_list = float('nan')\n",
    "\n",
    "        dict_[\"skills2\"].append(skill_list)\n",
    "\n",
    "        ## candidates\n",
    "        try:\n",
    "            candidates = list(job[\"candidates\"].values())[0]\n",
    "\n",
    "            candidate_list = []\n",
    "            for candidate in candidates:\n",
    "                try:\n",
    "                    candidate_item = candidate\n",
    "                except:\n",
    "                    candidate_item = float('nan')\n",
    "                candidate_list.append(candidate_item)\n",
    "        except:\n",
    "            candidate_list = float('nan')\n",
    "\n",
    "        dict_[\"candidates\"].append(candidate_list)\n",
    "\n",
    "        # Simple items\n",
    "\n",
    "        try:\n",
    "            assignments = job[\"assignments\"]\n",
    "        except:\n",
    "            assignments = float('nan')\n",
    "        dict_[\"assignments\"].append(assignments)    \n",
    "\n",
    "        try:\n",
    "            assignment_info = job[\"assignment_info\"]\n",
    "        except:\n",
    "            assignment_info = float('nan')\n",
    "        dict_[\"assignment_info\"].append(assignment_info)    \n",
    "\n",
    "        # project category sub-group\n",
    "        try:\n",
    "            category_2 = list(job[\"op_job_category_v2\"].values())[0][\"name\"]\n",
    "        except:\n",
    "            category_2 = float('nan')\n",
    "        dict_[\"category_2\"].append(category_2) \n",
    "\n",
    "        # project category main group\n",
    "        try:\n",
    "            category_1 = list(list(job[\"op_job_category_v2\"].values())[0][\"groups\"].values())[0]['name']\n",
    "        except:\n",
    "            category_1 = float('nan')\n",
    "        dict_[\"category_1\"].append(category_1) \n",
    "\n",
    "        try:\n",
    "            buyer = job[\"buyer\"]\n",
    "        except:\n",
    "            buyer = float('nan')\n",
    "        dict_[\"buyer\"].append(buyer) \n",
    "\n",
    "        try:\n",
    "            title = job[\"op_title\"]\n",
    "        except:\n",
    "            title = float('nan')\n",
    "        dict_[\"title\"].append(title)    \n",
    "\n",
    "        try:\n",
    "            description = job[\"op_description\"]\n",
    "        except:\n",
    "            description = float('nan')\n",
    "        dict_[\"description\"].append(description)\n",
    "\n",
    "        try:\n",
    "            worker_ID = job[\"ciphertext\"]\n",
    "        except:\n",
    "            worker_ID = float('nan')\n",
    "        dict_[\"worker_ID\"].append(worker_ID)\n",
    "\n",
    "        try:\n",
    "            op_engagement = job[\"op_engagement\"]\n",
    "        except:\n",
    "            op_engagement = float('nan')\n",
    "        dict_[\"op_engagement\"].append(op_engagement)\n",
    "\n",
    "        try:\n",
    "            engagement_weeks = job[\"engagement_weeks\"]\n",
    "        except:\n",
    "            engagement_weeks = float('nan')\n",
    "        dict_[\"engagement_weeks\"].append(engagement_weeks)   \n",
    "\n",
    "        try:\n",
    "            op_pref_english_skill = job[\"op_pref_english_skill\"]\n",
    "        except:\n",
    "            op_pref_english_skill = float('nan')\n",
    "        dict_[\"op_pref_english_skill\"].append(op_pref_english_skill)    \n",
    "\n",
    "        try:\n",
    "            date = job[\"op_ctime\"]\n",
    "        except:\n",
    "            date = float('nan')\n",
    "        dict_[\"date\"].append(date)\n",
    "\n",
    "        try:    \n",
    "            job_type =job[\"op_job_category_v2\"][\"op_job_category_v\"][\"name\"]\n",
    "        except:\n",
    "            job_type = float('nan')\n",
    "        dict_[\"job_type\"].append(job_type)\n",
    "\n",
    "        if job[\"job_type\"] == \"Hourly\":\n",
    "\n",
    "            try:\n",
    "                rate = (int(job[\"op_high_hourly_rate_all\"]) + int(job[\"op_low_hourly_rate_all\"])) *0.5\n",
    "                amount = float('nan')\n",
    "            except:\n",
    "                rate = float('nan')\n",
    "        else:\n",
    "            try:\n",
    "                amount = job[\"amount\"]\n",
    "            except:\n",
    "                amount = float('nan')\n",
    "            rate = float('nan')\n",
    "        \n",
    "        try:\n",
    "            dict_[\"rate\"].append(rate)\n",
    "            dict_[\"amount\"].append(amount)\n",
    "            \n",
    "        except:\n",
    "            dict_[\"rate\"].append(float('nan'))\n",
    "            dict_[\"amount\"].append(float('nan'))\n",
    "        \n",
    "        return dict_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform to dataframe and clean\n",
    "\n",
    "def to_dataframe(dict_):\n",
    "    \n",
    "    df = pd.DataFrame(dict([(k,pd.Series(v)) for k,v in dict_.items()]))\n",
    "    \n",
    "    # clean skills\n",
    "    df.skills.fillna(df.skills2, inplace=True)\n",
    "    del df['skills2']\n",
    "    \n",
    "    # Clean assignments and assignment_info columns\n",
    "    df = df.replace(r'^\\s*$', np.nan, regex=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_df(df):\n",
    "    \n",
    "    # limit to only hourly projects\n",
    "    df.rate = df.rate.fillna(-1)\n",
    "    fixed = df[ df['rate'] == -1].index\n",
    "    df.drop(fixed, inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    # Transform date (delete the last three zeros)\n",
    "    df.date = df.date.astype(int)\n",
    "    df.date = (df.date/1000).astype(int)\n",
    "    df['date_2'] = df.date.apply(lambda x: datetime.utcfromtimestamp(x).strftime('%Y-%m-%d'))\n",
    "    \n",
    "    # Extract buyer information\n",
    "\n",
    "    # Country of employer\n",
    "    country = []\n",
    "\n",
    "    for i in df.buyer.index:\n",
    "        try:\n",
    "            country.append(df.buyer[i]['op_country'])\n",
    "        except:\n",
    "            country.append(np.nan)\n",
    "\n",
    "    df['employer_country'] = country\n",
    "\n",
    "    # city of employer\n",
    "    city = []\n",
    "\n",
    "    for i in df.buyer.index:\n",
    "        try:\n",
    "            city.append(df.buyer[i]['op_city'])\n",
    "        except:\n",
    "            city.append(np.nan)\n",
    "\n",
    "    df['employer_city'] = city\n",
    "    \n",
    "    # drop assignment and candidate information\n",
    "    df.drop(columns=['candidates','assignments','assignment_info','buyer','amount'], inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000\n",
      "30000\n",
      "45000\n",
      "60000\n",
      "75000\n",
      "90000\n",
      "105000\n",
      "120000\n",
      "135000\n",
      "150000\n",
      "150001\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'df11' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-fb96400b9970>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m             \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclean_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_dataframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextract_data_large\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m             \u001b[0mdf11\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf11\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m             \u001b[0mdf11\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"csv/\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"chunk11\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\".csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mdf11\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df11' is not defined"
     ]
    }
   ],
   "source": [
    "df1 = pd.DataFrame()\n",
    "df2 = pd.DataFrame()\n",
    "df3 = pd.DataFrame()\n",
    "df4 = pd.DataFrame()\n",
    "df5 = pd.DataFrame()\n",
    "df6 = pd.DataFrame()\n",
    "df7 = pd.DataFrame()\n",
    "df8 = pd.DataFrame()\n",
    "df9 = pd.DataFrame()\n",
    "df10 = pd.DataFrame()\n",
    "df11 = pd.DataFrame()\n",
    "\n",
    "with open(\"results_4_to_10.txt\") as f:\n",
    "    \n",
    "    for number,line in enumerate(f):\n",
    "        \n",
    "        # chunk 1\n",
    "        if number < 15000:\n",
    "            df = clean_df(to_dataframe(extract_data_large(line)))\n",
    "            df1 = df1.append(df)\n",
    "        \n",
    "        elif number == 15000:\n",
    "            df = clean_df(to_dataframe(extract_data_large(line)))\n",
    "            df1 = df1.append(df)\n",
    "            df1.to_csv(\"csv/\" + \"chunk1\"+\".csv\", index= False)\n",
    "            del df1\n",
    "            print(number)\n",
    "            \n",
    "        # chunk 2\n",
    "        elif 15000 < number < 30000:\n",
    "            df = clean_df(to_dataframe(extract_data_large(line)))\n",
    "            df2 = df2.append(df)\n",
    "        \n",
    "        elif number == 30000:\n",
    "            df = clean_df(to_dataframe(extract_data_large(line)))\n",
    "            df2 = df2.append(df)\n",
    "            df2.to_csv(\"csv/\" + \"chunk2\"+\".csv\", index= False)\n",
    "            del df2\n",
    "            print(number)\n",
    "            \n",
    "        # chunk 3\n",
    "        elif 30000 < number < 45000:\n",
    "            df = clean_df(to_dataframe(extract_data_large(line)))\n",
    "            df3 = df3.append(df)\n",
    "        \n",
    "        elif number == 45000:\n",
    "            df = clean_df(to_dataframe(extract_data_large(line)))\n",
    "            df3 = df3.append(df)\n",
    "            df3.to_csv(\"csv/\" + \"chunk3\"+\".csv\", index= False)\n",
    "            del df3\n",
    "            print(number)\n",
    "            \n",
    "        # chunk 4\n",
    "        elif 45000 < number < 60000:\n",
    "            df = clean_df(to_dataframe(extract_data_large(line)))\n",
    "            df4 = df4.append(df)\n",
    "        \n",
    "        elif number == 60000:\n",
    "            df = clean_df(to_dataframe(extract_data_large(line)))\n",
    "            df4 = df4.append(df)\n",
    "            df4.to_csv(\"csv/\" + \"chunk4\"+\".csv\", index= False)\n",
    "            del df4\n",
    "            print(number)\n",
    "\n",
    "        # chunk 5\n",
    "        elif 60000 < number < 75000:\n",
    "            df = clean_df(to_dataframe(extract_data_large(line)))\n",
    "            df5 = df5.append(df)\n",
    "        \n",
    "        elif number == 75000:\n",
    "            df = clean_df(to_dataframe(extract_data_large(line)))\n",
    "            df5 = df5.append(df)\n",
    "            df5.to_csv(\"csv/\" + \"chunk5\"+\".csv\", index= False)\n",
    "            del df5\n",
    "            print(number)\n",
    "            \n",
    "        # chunk 5\n",
    "        elif 60000 < number < 75000:\n",
    "            df = clean_df(to_dataframe(extract_data_large(line)))\n",
    "            df5 = df5.append(df)\n",
    "        \n",
    "        elif number == 75000:\n",
    "            df = clean_df(to_dataframe(extract_data_large(line)))\n",
    "            df5 = df5.append(df)\n",
    "            df5.to_csv(\"csv/\" + \"chunk5\"+\".csv\", index= False)\n",
    "            del df5\n",
    "            print(number)\n",
    "        \n",
    "        # chunk 6\n",
    "        elif 75000 < number < 90000:\n",
    "            df = clean_df(to_dataframe(extract_data_large(line)))\n",
    "            df6 = df6.append(df)\n",
    "        \n",
    "        elif number == 90000:\n",
    "            df = clean_df(to_dataframe(extract_data_large(line)))\n",
    "            df6 = df6.append(df)\n",
    "            df6.to_csv(\"csv/\" + \"chunk6\"+\".csv\", index= False)\n",
    "            del df6\n",
    "            print(number)\n",
    "\n",
    "        # chunk 7\n",
    "        elif 90000 < number < 105000:\n",
    "            df = clean_df(to_dataframe(extract_data_large(line)))\n",
    "            df7 = df7.append(df)\n",
    "        \n",
    "        elif number == 105000:\n",
    "            df = clean_df(to_dataframe(extract_data_large(line)))\n",
    "            df7 = df7.append(df)\n",
    "            df7.to_csv(\"csv/\" + \"chunk7\"+\".csv\", index= False)\n",
    "            del df7\n",
    "            print(number)\n",
    "            \n",
    "        # chunk 8\n",
    "        elif 105000 < number < 120000:\n",
    "            df = clean_df(to_dataframe(extract_data_large(line)))\n",
    "            df8 = df8.append(df)\n",
    "        \n",
    "        elif number == 120000:\n",
    "            df = clean_df(to_dataframe(extract_data_large(line)))\n",
    "            df8 = df8.append(df)\n",
    "            df8.to_csv(\"csv/\" + \"chunk8\"+\".csv\", index= False)\n",
    "            del df8\n",
    "            print(number)\n",
    "            \n",
    "        # chunk 9\n",
    "        elif 120000 < number < 135000:\n",
    "            df = clean_df(to_dataframe(extract_data_large(line)))\n",
    "            df9 = df9.append(df)\n",
    "        \n",
    "        elif number == 135000:\n",
    "            df = clean_df(to_dataframe(extract_data_large(line)))\n",
    "            df9 = df9.append(df)\n",
    "            df9.to_csv(\"csv/\" + \"chunk9\"+\".csv\", index= False)\n",
    "            del df9\n",
    "            print(number)\n",
    "\n",
    "        # chunk 10\n",
    "        elif 135000 < number < 150000:\n",
    "            df = clean_df(to_dataframe(extract_data_large(line)))\n",
    "            df10 = df10.append(df)\n",
    "        \n",
    "        elif number == 150000:\n",
    "            df = clean_df(to_dataframe(extract_data_large(line)))\n",
    "            df10 = df10.append(df)\n",
    "            df10.to_csv(\"csv/\" + \"chunk10\"+\".csv\", index= False)\n",
    "            del df10\n",
    "            print(number)     \n",
    "        \n",
    "        # chunk 11\n",
    "        else:\n",
    "            df = clean_df(to_dataframe(extract_data_large(line)))\n",
    "            df11 = df11.append(df)\n",
    "            df11.to_csv(\"csv/\" + \"chunk11\"+\".csv\", index= False)\n",
    "            del df11\n",
    "            print(number) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second Half"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "165000\n",
      "180000\n"
     ]
    }
   ],
   "source": [
    "df11 = pd.DataFrame()\n",
    "df12 = pd.DataFrame()\n",
    "df13 = pd.DataFrame()\n",
    "\n",
    "\n",
    "with open(\"results_4_to_10.txt\") as f:\n",
    "    \n",
    "    for number,line in enumerate(f):\n",
    "        \n",
    "        if number < 150000:\n",
    "            pass\n",
    "        \n",
    "        # chunk 11\n",
    "        elif 150000 < number < 165000:\n",
    "            df = clean_df(to_dataframe(extract_data_large(line)))\n",
    "            df11 = df11.append(df)\n",
    "        \n",
    "        elif number == 165000:\n",
    "            df = clean_df(to_dataframe(extract_data_large(line)))\n",
    "            df11 = df11.append(df)\n",
    "            df11.to_csv(\"csv/\" + \"chunk11\"+\".csv\", index= False)\n",
    "            del df11\n",
    "            print(number)\n",
    "            \n",
    "        # chunk 12\n",
    "        elif 165000 < number < 180000:\n",
    "            df = clean_df(to_dataframe(extract_data_large(line)))\n",
    "            df12 = df12.append(df)\n",
    "        \n",
    "        elif number == 180000:\n",
    "            df = clean_df(to_dataframe(extract_data_large(line)))\n",
    "            df12 = df12.append(df)\n",
    "            df12.to_csv(\"csv/\" + \"chunk12\"+\".csv\", index= False)\n",
    "            del df12\n",
    "            print(number)\n",
    "            \n",
    "        # chunk 13\n",
    "        elif 180000 < number < 184146:\n",
    "            df = clean_df(to_dataframe(extract_data_large(line)))\n",
    "            df13 = df13.append(df)\n",
    "        \n",
    "        elif number == 184146:\n",
    "            df = clean_df(to_dataframe(extract_data_large(line)))\n",
    "            df13 = df13.append(df)\n",
    "            df13.to_csv(\"csv/\" + \"chunk13\"+\".csv\", index= False)\n",
    "            #del df13\n",
    "            print(number)\n",
    "\n",
    "        else:\n",
    "            pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
