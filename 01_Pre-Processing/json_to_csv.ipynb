{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transforming the raw data into .csv format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Information that could become relevant but is still missing:\n",
    "\n",
    "* totals hours (Hourly projects)\n",
    "* Total value of hourly projects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Required libraries and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import ast\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open data line by line\n",
    "\n",
    "def open_file(filename):\n",
    "    with open(os.getcwd() + filename, \"r\") as fp:\n",
    "        lines = fp.readlines()\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract data from json and save as dict\n",
    "\n",
    "def extract_data(rawdata):\n",
    "    \n",
    "    dict_ = {\"skills\":[],\"skills2\":[], \"rate\":[], \"amount\":[], \"job_type\":[], \"date\":[], \"description\":[],\n",
    "         \"title\":[], \"worker_ID\":[], \"op_engagement\":[], \"engagement_weeks\":[],\n",
    "         \"op_pref_english_skill\":[],\"candidates\":[], \"buyer\":[],\"category_1\":[],\"category_2\":[],\n",
    "        \"assignments\":[],\"assignment_info\":[]}\n",
    "    \n",
    "    for i in range(0,len(rawdata)):\n",
    "        job = ast.literal_eval(rawdata[i])\n",
    "\n",
    "        # multiple items\n",
    "\n",
    "        ## skills 1\n",
    "\n",
    "        try:\n",
    "            skills = list(job[\"op_required_skills\"][\"op_required_skill\"].values())[0]\n",
    "        except:\n",
    "            skills = float('nan')\n",
    "        dict_[\"skills\"].append(skills)\n",
    "\n",
    "        ## skills multiple\n",
    "        try:\n",
    "            skills2 = job[\"op_required_skills\"][\"op_required_skill\"]\n",
    "            skill_list = []\n",
    "            for skill in skills2:\n",
    "                try:\n",
    "                    skill_item = list(skill.values())[0]\n",
    "                except:\n",
    "                    skill_item = float('nan')\n",
    "                skill_list.append(skill_item)\n",
    "        except:\n",
    "            skill_list = float('nan')\n",
    "\n",
    "        dict_[\"skills2\"].append(skill_list)\n",
    "\n",
    "        ## candidates\n",
    "        try:\n",
    "            candidates = list(job[\"candidates\"].values())[0]\n",
    "\n",
    "            candidate_list = []\n",
    "            for candidate in candidates:\n",
    "                try:\n",
    "                    candidate_item = candidate\n",
    "                except:\n",
    "                    candidate_item = float('nan')\n",
    "                candidate_list.append(candidate_item)\n",
    "        except:\n",
    "            candidate_list = float('nan')\n",
    "\n",
    "        dict_[\"candidates\"].append(candidate_list)\n",
    "\n",
    "        # Simple items\n",
    "\n",
    "        try:\n",
    "            assignments = job[\"assignments\"]\n",
    "        except:\n",
    "            assignments = float('nan')\n",
    "        dict_[\"assignments\"].append(assignments)    \n",
    "\n",
    "        try:\n",
    "            assignment_info = job[\"assignment_info\"]\n",
    "        except:\n",
    "            assignment_info = float('nan')\n",
    "        dict_[\"assignment_info\"].append(assignment_info)    \n",
    "\n",
    "        # project category sub-group\n",
    "        try:\n",
    "            category_2 = list(job[\"op_job_category_v2\"].values())[0][\"name\"]\n",
    "        except:\n",
    "            category_2 = float('nan')\n",
    "        dict_[\"category_2\"].append(category_2) \n",
    "\n",
    "        # project category main group\n",
    "        try:\n",
    "            category_1 = list(list(job[\"op_job_category_v2\"].values())[0][\"groups\"].values())[0]['name']\n",
    "        except:\n",
    "            category_1 = float('nan')\n",
    "        dict_[\"category_1\"].append(category_1) \n",
    "\n",
    "        try:\n",
    "            buyer = job[\"buyer\"]\n",
    "        except:\n",
    "            buyer = float('nan')\n",
    "        dict_[\"buyer\"].append(buyer) \n",
    "\n",
    "        try:\n",
    "            title = job[\"op_title\"]\n",
    "        except:\n",
    "            title = float('nan')\n",
    "        dict_[\"title\"].append(title)    \n",
    "\n",
    "        try:\n",
    "            description = job[\"op_description\"]\n",
    "        except:\n",
    "            description = float('nan')\n",
    "        dict_[\"description\"].append(description)\n",
    "\n",
    "        try:\n",
    "            worker_ID = job[\"ciphertext\"]\n",
    "        except:\n",
    "            worker_ID = float('nan')\n",
    "        dict_[\"worker_ID\"].append(worker_ID)\n",
    "\n",
    "        try:\n",
    "            op_engagement = job[\"op_engagement\"]\n",
    "        except:\n",
    "            op_engagement = float('nan')\n",
    "        dict_[\"op_engagement\"].append(op_engagement)\n",
    "\n",
    "        try:\n",
    "            engagement_weeks = job[\"engagement_weeks\"]\n",
    "        except:\n",
    "            engagement_weeks = float('nan')\n",
    "        dict_[\"engagement_weeks\"].append(engagement_weeks)   \n",
    "\n",
    "        try:\n",
    "            op_pref_english_skill = job[\"op_pref_english_skill\"]\n",
    "        except:\n",
    "            op_pref_english_skill = float('nan')\n",
    "        dict_[\"op_pref_english_skill\"].append(op_pref_english_skill)    \n",
    "\n",
    "        try:\n",
    "            date = job[\"op_ctime\"]\n",
    "        except:\n",
    "            date = float('nan')\n",
    "        dict_[\"date\"].append(date)\n",
    "\n",
    "        try:    \n",
    "            job_type =job[\"op_job_category_v2\"][\"op_job_category_v\"][\"name\"]\n",
    "        except:\n",
    "            job_type = float('nan')\n",
    "        dict_[\"job_type\"].append(job_type)\n",
    "\n",
    "        if job[\"job_type\"] == \"Hourly\":\n",
    "\n",
    "            try:\n",
    "                rate = (int(job[\"op_high_hourly_rate_all\"]) + int(job[\"op_low_hourly_rate_all\"])) *0.5\n",
    "                amount = float('nan')\n",
    "            except:\n",
    "                rate = float('nan')\n",
    "        else:\n",
    "            try:\n",
    "                amount = job[\"amount\"]\n",
    "            except:\n",
    "                amount = float('nan')\n",
    "            rate = float('nan')\n",
    "        dict_[\"rate\"].append(rate)\n",
    "        dict_[\"amount\"].append(amount)\n",
    "    \n",
    "    return(dict_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform to dataframe and clean\n",
    "\n",
    "def to_clean_df(dict_):\n",
    "    \n",
    "    df = pd.DataFrame(dict([(k,pd.Series(v)) for k,v in dict_.items()]))\n",
    "    \n",
    "    # clean skills\n",
    "    df.skills.fillna(df.skills2, inplace=True)\n",
    "    del df['skills2']\n",
    "    \n",
    "    # Clean assignments and assignment_info columns\n",
    "    df = df.replace(r'^\\s*$', np.nan, regex=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-91af099edb4e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Write to csv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"project_data.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# Write to csv\n",
    "\n",
    "# df.to_csv(\"project_data.csv\", index= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application to raw data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Single file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = to_clean_df(extract_data(open_file(\"/results_day_1_to_3.txt\")))\n",
    "\n",
    "df.to_csv(\"project_data_1_to_3.csv\", index= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Folder structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: For this to work the notebook has to be placed where the results folders are!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open results.txt in each folder, load and transform the data. Then save the data as .csv in a new folder (reason: better overview while keeping smaller file sizes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def substract(a, b):                              \n",
    "    return \"\".join(a.rsplit(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Succesfully transformed jobids_40\n",
      "Succesfully transformed jobids_41\n",
      "Succesfully transformed csv_data\n"
     ]
    }
   ],
   "source": [
    "# Get Folder and file names\n",
    "files = glob.glob(os.getcwd()+\"/*/results.txt\")\n",
    "folders = glob.glob(os.getcwd()+\"/*/\")\n",
    "\n",
    "# Create new folder for results\n",
    "try:\n",
    "    os.mkdir(os.getcwd()+\"/csv_data\")\n",
    "except FileExistsError:\n",
    "    pass\n",
    "\n",
    "# Transform data\n",
    "for num, file in enumerate(files):\n",
    "    \n",
    "    # extract data\n",
    "    with open(file, \"r\") as fp:\n",
    "        lines = fp.readlines()\n",
    "    \n",
    "    dict_ = extract_data(lines)\n",
    "    \n",
    "    df = to_clean_df(dict_)\n",
    "    \n",
    "    # get new file name\n",
    "    name = substract(substract(folders[num],os.getcwd()),\"/\")\n",
    "    \n",
    "    # save as .csv\n",
    "    df.to_csv(\"csv_data/\" + name + \".csv\", index= False)\n",
    "    \n",
    "    print(\"Succesfully transformed\", name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
